## 记录日常中遇到的问题
1.Logit回归
2.SVM
3.判别式模型与生成式模型的区别

##### 1.Logit回归
Logit回归本质上是一种根据样本对权值进行极大似然估计的方法，
而后验概率正比于先验概率和似然函数的乘积。logit仅仅是最大化似然函数;<br/>
Logit回归的输出就是样本属于正类别的几率，可以计算出概率


##### 2.SVM

SVM的目标是找到使得训练数据尽可能分开且分类间隔最大的超平面，属于结构风险最小化;<br/>
SVM可以通过正则化系数控制模型的复杂度，避免过拟合。
- - -
经常使用的核函数:
核函数的定义并不困难，根据泛函的有关理论，只要一种函数 K ( x i , x j )
满足Mercer条件，它就对应某一变换空间的内积．对于判断哪些函数是核函数到目前为止
也取得了重要的突破，得到Mercer定理和以下常用的核函数类型：<br/>
(1)线性核函数<br/>
K ( x , x i ) = x ⋅ x i

(2)多项式核<br/>
K ( x , x i ) = ( ( x ⋅ x i ) + 1 ) d

(3)径向基核（RBF）<br/>
K ( x , x i ) = exp ( − ∥ x − x i ∥ 2 σ 2 )
Gauss径向基函数则是局部性强的核函数，其外推能力随着参数 σ 的增大而减弱。
多项式形式的核函数具有良好的全局性质。局部性较差。

(4)傅里叶核<br/>
K ( x , x i ) = 1 − q 2 2 ( 1 − 2 q cos ( x − x i ) + q 2 )

(5)样条核<br/>
K ( x , x i ) = B 2 n + 1 ( x − x i )

(6)Sigmoid核函数<br/>
K ( x , x i ) = tanh ( κ ( x , x i ) − δ )


##### 3.判别式模型与生成式模型的区别
产生式模型(Generative Model)与判别式模型(Discrimitive Model)是分类器常遇到的概念，它们的区别在于：

对于输入x，类别标签y：
产生式模型估计它们的联合概率分布P(x,y)
判别式模型估计条件概率分布P(y|x)

产生式模型可以根据贝叶斯公式得到判别式模型，但反过来不行。
