### 线性回归的损失函数是凸函数的证明

假设有$$I$$个训练样本，特征向量为$${x_i}$$，标签值为$${y_i}$$，使用均方误差（MSE），线性回归训练时优化的目标为：

$$L = \frac{1}{{2l}}\sum\limits_{i = 1}^l {{{({w^T}{x_i} - {y_i})}^2}} $$

损失函数对权重向量w的一阶偏导数为：

$$\frac{{\partial L}}{{\partial {w_i}}} = \frac{1}{{2l}}\sum\limits_{k = 1}^l {2({w^T}{x_k} - {y_k})} \frac{{\partial {w^T}{x_k}}}{{\partial {x_i}}} = \frac{1}{l}\sum\limits_{k = 1}^l {({w^T}{x_k} - {y_k})} {x_{ki}}$$

损失函数对权重向量w的二阶偏导数为：

$$\frac{{{\partial ^2}L}}{{\partial {w_i}\partial {w_j}}} = \frac{{\partial \frac{1}{l}\sum\limits_{k = 1}^l {({w^T}{x_k} - {y_k})} {x_{ki}}}}{{\partial {w_j}}} = \frac{{\partial \frac{1}{l}\sum\limits_{k = 1}^l {{w^T}{x_k}{x_{ki}}} }}{{\partial {w_j}}} = \frac{{\partial \frac{1}{l}\sum\limits_{k = 1}^l {\left( {\sum\limits_{p = 1}^n {{w_p}{w_{kp}}} } \right){x_{ki}}} }}{{\partial {w_j}}} = \frac{1}{l}\sum\limits_{k = 1}^l {{x_{kj}}{x_{ki}}} $$

因此目标函数的Hessian矩阵为：

![640](.\线性回归的损失函数是凸函数的证明.assets/640.webp)



写成矩阵形式为：

![1](.\线性回归的损失函数是凸函数的证明.assets/1.webp)



其中X是所有样本的特征向量按照列构成的矩阵，对于任意不为0的向量x,有：

![2](.\线性回归的损失函数是凸函数的证明.assets/2.webp)

因此Hessian矩阵是半正定的，目标函数是凸函数。